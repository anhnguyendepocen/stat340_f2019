---
title: "Model Comparison Example Wrap-Up"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Recall we fit a line, a parabola, and a degree 9 polynomial to model the relationship between a car's weight (`Weight`) and its fuel efficiency (`MPG`).

We fit these models to 10 cars that were selected from a larger data set of 38 cars.  These 10 cars are the **training set**: they were used to **train** the model, or estimate the model parameters.

The remaining 28 cars can be used as a **test set**: a set of observations that were *not* used in model estimation, and can therefore be used to independently check the quality of the model fit.

The train and test set are labeled as such in the plot below.

```{r, fig.height = 3, fig.width = 6, message=FALSE, warning=FALSE}
library(dplyr) # for data manipulation functions
library(tidyr) # for data manipulation functions
library(readr) # for read_csv, which can read csv files from the internet
library(ggplot2) # for making plots
library(gridExtra) # for grid.arrange, which arranges the plots next to each other
library(polynom) # for obtaining the third polynomial fit below

cars <- read_csv("http://www.evanlray.com/data/sdm4/Cars.csv")
train_inds <- c(1, 6, 8, 14, 15, 16, 21, 32, 33, 37)
train_cars <- cars %>% slice(train_inds) # 10 observations to use in getting fits below.

cars$train_test <- "test"
cars$train_test[train_inds] <- "train"

ggplot() + 
  geom_point(data = cars, mapping = aes(x = Weight, y = MPG, color = train_test)) +
  scale_color_manual(breaks = c("test", "train"), values = c("black", "red"))
```

\newpage

Here are the plots again, over both the training and test sets.  The estimated curves are shown in red, to indicate that they were fit to the training data set.

```{r, fig.height = 3.75, echo = FALSE, message=FALSE, warning=FALSE}
lm1 <- lm(MPG ~ Weight, data = train_cars)
predict_1 <- function(x) {
  predict(lm1, data.frame(Weight = x))
}

p1 <- ggplot(data = cars, mapping = aes(x = Weight, y = MPG, color = train_test)) + 
  geom_point() +
  scale_color_manual(breaks = c("test", "train"), values = c("black", "red")) +
  stat_function(fun = predict_1, color = "red") +
  ggtitle("linear fit")

lm2 <- lm(MPG ~ Weight + I(Weight^2), data = train_cars)
predict_2 <- function(x) {
  predict(lm2, data.frame(Weight = x))
}

p2 <- ggplot(data = cars, mapping = aes(x = Weight, y = MPG, color = train_test)) + 
  geom_point() +
  scale_color_manual(breaks = c("test", "train"), values = c("black", "red")) +
  stat_function(fun = predict_2, color = "red") +
  ggtitle("quadratic fit")

# Our degree 9 polynomial fit is not obtained from lm (although you could do that too)
# You don't need to know how to use the poly.calc function.
fit9 <- poly.calc(train_cars$Weight, train_cars$MPG)
predict_9 <- as.function(fit9)

p3 <- ggplot(data = cars, mapping = aes(x = Weight, y = MPG, color = train_test)) + 
  geom_point() +
  scale_color_manual(breaks = c("test", "train"), values = c("black", "red")) +
  stat_function(fun = predict_9, n = 1000001, color = "red") +
  ylim(c(15, 40)) +
  ggtitle("degree 9 fit, zoomed in")

p4 <- ggplot(data = cars, mapping = aes(x = Weight, y = MPG, color = train_test)) + 
  geom_point() +
  scale_color_manual(breaks = c("test", "train"), values = c("black", "red")) +
  stat_function(fun = predict_9, n = 100001, color = "red") +
  ggtitle("degree 9 fit, zoomed out")

grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
```


Below is R code for calculating and plotting the Mean Squared Error (MSE), separately for the train and test sets for each of our three candidate models:

$$MSE = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y})^2 = \frac{1}{n}SSR$$

The MSE contains the exact same information as SSR but doesn't grow with the sample size.  This means it's more comparable across data sets of different sizes.

```{r}
cars_residuals <- cars %>%
  mutate(
    residual_linear = MPG - predict_1(Weight),
    residual_quadratic = MPG - predict_2(Weight),
    residual_degree9 = MPG - predict_9(Weight)
  )

model_residual_summaries <- 
  rbind(
    cars_residuals %>%
      dplyr::group_by(train_test) %>%
      dplyr::summarize(
        MSE = mean(residual_linear^2),
      ) %>%
      dplyr::mutate(
        degree = "1"
      ),
    cars_residuals %>%
      dplyr::group_by(train_test) %>%
      dplyr::summarize(
        MSE = mean(residual_quadratic^2),
      ) %>%
      dplyr::mutate(
        degree = "2"
      ),
    cars_residuals %>%
      dplyr::group_by(train_test) %>%
      dplyr::summarize(
        MSE = mean(residual_degree9^2),
      ) %>%
      dplyr::mutate(
        degree = "9"
      )
  )

model_residual_summaries
```

```{r, fig.height=3}
ggplot(data = model_residual_summaries) +
  geom_point(mapping = aes(x = degree, y = MSE)) + 
  facet_wrap( ~ train_test, scales = "free")
```
